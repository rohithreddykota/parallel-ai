{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/__init__.py:7: UserWarning: Dask-XGBoost has been deprecated and is no longer maintained. The functionality of this project has been included directly in XGBoost. To use Dask and XGBoost together, please use ``xgboost.dask`` instead https://xgboost.readthedocs.io/en/latest/tutorials/dask.html.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dask_ml.metrics import mean_squared_error, r2_score\n",
    "import dask.array as da\n",
    "from distributed import default_client\n",
    "import dask.dataframe as dd\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from dask_ml.xgboost import XGBRegressor\n",
    "\n",
    "# from dask_ml.ensemble import RandomForestRegressor\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "from dask.distributed import get_client, Client\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import dask.array as da\n",
    "from dask.distributed import Client\n",
    "import xgboost as xgb\n",
    "from dask_ml.model_selection import GridSearchCV, train_test_split\n",
    "from dask_ml.metrics import mean_squared_error\n",
    "from dask_ml.wrappers import ParallelPostFit\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from dask.distributed import Client\n",
    "import joblib\n",
    "import dask.array as da\n",
    "import xgboost as xgb\n",
    "from dask_ml.model_selection import GridSearchCV, train_test_split\n",
    "from dask_ml.metrics import mean_squared_error\n",
    "from dask_ml.wrappers import ParallelPostFit\n",
    "import numpy as np\n",
    "from dask_ml.xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "def print_dask_df_info(dask_df):\n",
    "    \"\"\"\n",
    "    Prints comprehensive information about a Dask DataFrame including:\n",
    "    - Number of partitions\n",
    "    - Memory usage of each partition\n",
    "    - Division information\n",
    "    - Column data types\n",
    "    \"\"\"\n",
    "    # Ensure the input is a Dask DataFrame\n",
    "    if not isinstance(dask_df, dd.DataFrame):\n",
    "        print(\"The input is not a Dask DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Number of partitions\n",
    "    num_partitions = dask_df.npartitions\n",
    "    print(f'Number of partitions: {num_partitions}')\n",
    "\n",
    "    # Memory usage of each partition\n",
    "    try:\n",
    "        partition_memory_usage = dask_df.memory_usage(deep=True).compute()\n",
    "        print('Partition memory usage (in MB):\\n', partition_memory_usage/1024/1024)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not compute memory usage: {e}\")\n",
    "\n",
    "    # # Division information\n",
    "    # division_info = dask_df.divisions\n",
    "    # print('Division information:', division_info)\n",
    "\n",
    "    # Column data types\n",
    "    dtypes = dask_df.dtypes\n",
    "    print('Column data types:\\n', dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, get_client\n",
    "from functools import wraps\n",
    "import time\n",
    "\n",
    "def with_execution_info(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Ensure a Dask Client is available or create a new one\n",
    "        try:\n",
    "            client = get_client()\n",
    "        except ValueError:\n",
    "            client = Client()\n",
    "            print(\"Initialized a new Dask Client.\")\n",
    "        \n",
    "        # Get Dask Worker details\n",
    "        workers = client.scheduler_info()['workers']\n",
    "        cpus = sum(worker['nthreads'] for worker in workers.values())\n",
    "        threads = len(workers)\n",
    "\n",
    "        # Measure function execution time\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        execution_time = time.time() - start_time\n",
    "\n",
    "        # Information dictionary\n",
    "        info = {\n",
    "            'result': result,\n",
    "            'execution_time': execution_time,\n",
    "            'total_cpus': cpus,\n",
    "            'total_threads': threads,\n",
    "        }\n",
    "        \n",
    "        return info\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_partition_info(dask_df):\n",
    "    \"\"\"\n",
    "    Retrieves information about the partitions of a Dask DataFrame including:\n",
    "    - Total number of partitions\n",
    "    - Number of rows in each partition\n",
    "    - Estimated memory usage of each partition in bytes\n",
    "    \n",
    "    Parameters:\n",
    "    - dask_df: A Dask DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    A summary dictionary with partition information.\n",
    "    \"\"\"\n",
    "    if not isinstance(dask_df, dd.DataFrame):\n",
    "        raise ValueError(\"The input must be a Dask DataFrame.\")\n",
    "    \n",
    "    # Function to compute rows in each partition\n",
    "    def count_rows(partition):\n",
    "        return len(partition)\n",
    "    \n",
    "    # Function to compute memory usage in each partition\n",
    "    def get_memory_usage(partition):\n",
    "        return partition.memory_usage(deep=True).sum()\n",
    "    \n",
    "    # Calculating partition info\n",
    "    num_partitions = dask_df.npartitions\n",
    "    rows_per_partition = dask_df.map_partitions(count_rows).compute().tolist()\n",
    "    memory_usage_per_partition = dask_df.map_partitions(get_memory_usage).compute().tolist()\n",
    "    \n",
    "    # Constructing the summary dictionary\n",
    "    partition_info = {\n",
    "        \"total_partitions\": num_partitions,\n",
    "        \"rows_per_partition\": rows_per_partition,\n",
    "        \"memory_usage_per_partition_bytes\": memory_usage_per_partition,\n",
    "    }\n",
    "    \n",
    "    return partition_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_repartition(mem='32MB', *args):\n",
    "  \"\"\"\n",
    "  This function repartitions the input Dask DataFrames/Series to the specified memory size.\n",
    "  \"\"\"\n",
    "  if len(args) == 0:\n",
    "    raise ValueError(\"No input Dask DataFrames/Series provided.\")\n",
    "  \n",
    "  if not isinstance(mem, str):\n",
    "    raise ValueError(\"The memory size must be a string.\")\n",
    "  for i in args:\n",
    "    if not isinstance(i, (dd.DataFrame, dd.Series)):\n",
    "      raise ValueError(\"The input must be a Dask DataFrame or Series.\")\n",
    "    i = i.repartition(partition_size=mem)\n",
    "  return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dask_client(cpus=4, threads=1, memory='2GB'):\n",
    "    try:\n",
    "        # Attempt to get the current client\n",
    "        client = get_client()\n",
    "        # If successful, restart the client\n",
    "        print(\"Restarting existing Dask Client...\")\n",
    "        client.close()\n",
    "        print(\"Dask Client restarted.\")\n",
    "    except ValueError:\n",
    "        pass\n",
    "        # client = Client(n_workers=cpus, threads_per_worker=2, processes=True, memory_limit='2GB')\n",
    "    client = Client(n_workers=cpus, threads_per_worker=threads, processes=True, memory_limit=memory)\n",
    "    print(\"Dashboard link:\", client.dashboard_link)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir='data/*.part', blocksize='32MB', partition_size='32MB'):\n",
    "    df = dd.read_csv(dir, blocksize=blocksize)\n",
    "    df = df.repartition(partition_size=partition_size)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_test_split(df, test_size=0.3):\n",
    "  df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "  X = df[df.columns[3:]]\n",
    "  X = X.drop([\"pickup_day_of_week\", \"eucledian_distance\"], axis=1)\n",
    "  y = df[\"fare_amount\"].to_frame()  \n",
    "  # todo - check if we need to convert to dask array\n",
    "  X, y = X.to_dask_array(lengths=True), y.to_dask_array(lengths=True)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "  return X_train, X_test, y_train, y_test\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = create_dask_client(cpus=4, threads=1, memory='2GB')\n",
    "# train = load_data('final_data.csv/*.part')\n",
    "# X_train, X_test, y_train, y_test = prepare_train_test_split(train)\n",
    "\n",
    "# print_dask_df_info(X_train)\n",
    "# partition_info = get_partition_info(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegressionWith(cpus=1, threads=1, mem_per_partition='32MB', load_block_size='32MB', partition_size='32MB'):\n",
    "  \n",
    "  create_dask_client(cpus=cpus, threads=threads, memory=mem_per_partition)\n",
    "  train = load_data('train_data_head.csv', blocksize=load_block_size, partition_size=partition_size)\n",
    "  X_train, X_test, y_train, y_test = prepare_train_test_split(train)\n",
    "  lr = LinearRegression(solver_kwargs={\"normalize\":False})\n",
    "  lr_fit = lambda lr, X_train, y_train: lr.fit(X_train, y_train)\n",
    "  \n",
    "  fit = with_execution_info(lr_fit)\n",
    "  \n",
    "  info = fit(lr, X_train, y_train)\n",
    "\n",
    "  lr_y_pred = lr.predict(X_test)\n",
    "  mse = mean_squared_error(y_test, lr_y_pred)\n",
    "  rmse = da.sqrt(mse)  # Compute RMSE from MSE\n",
    "  r2 = r2_score(y_test, lr_y_pred)  # Compute R²\n",
    "\n",
    "  print(f\"RMSE: {rmse}\")\n",
    "  print(f\"R² score: {r2}\")\n",
    "\n",
    "\n",
    "  with joblib.parallel_backend(\"dask\"):\n",
    "      scores = cross_val_score(lr, X_train, y_train, cv=5)\n",
    "\n",
    "  print(f\"Cross-validation scores: {scores}\")\n",
    "  print(f\"Average score: {scores.mean()}\")\n",
    "  \n",
    "  info['rmse'] = rmse\n",
    "  info['r2'] = r2\n",
    "  info['cross_val_scores'] = scores\n",
    "  info['average_score'] = scores.mean()\n",
    "  return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 50331 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard link: http://127.0.0.1:50331/status\n",
      "RMSE: 2.3281079024853883\n",
      "R² score: -1.4518910151589477\n",
      "Cross-validation scores: [0.35637573        nan        nan        nan        nan]\n",
      "Average score: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'result': LinearRegression(solver_kwargs={'normalize': False}),\n",
       " 'execution_time': 0.6264269351959229,\n",
       " 'total_cpus': 1,\n",
       " 'total_threads': 1,\n",
       " 'rmse': 2.3281079024853883,\n",
       " 'r2': -1.4518910151589477,\n",
       " 'cross_val_scores': array([0.35637573,        nan,        nan,        nan,        nan]),\n",
       " 'average_score': nan}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearRegressionWith(cpus=1, threads=1, mem_per_partition='2GB', load_block_size='32MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def xgbWith(cpus=1, threads=1, mem_per_partition='32MB', load_block_size='32MB', partition_size='32MB'):\n",
    "  \n",
    "  create_dask_client(cpus=cpus, threads=threads, memory=mem_per_partition)\n",
    "  # train = load_data('final_data.csv/0*.part', blocksize=load_block_size, partition_size=partition_size)\n",
    "  train = load_data('train_data_head.csv', blocksize=load_block_size, partition_size=partition_size)\n",
    "  X_train, X_test, y_train, y_test = prepare_train_test_split(train)\n",
    "  xgb = XGBRegressor()\n",
    "  xgb_fit = lambda xgb, X_train, y_train: xgb.fit(X_train, y_train)\n",
    "  \n",
    "  fit = with_execution_info(xgb_fit)\n",
    "  \n",
    "  info = fit(xgb, X_train, y_train)\n",
    "\n",
    "  xgb_y_pred = xgb.predict(X_test)\n",
    "  mse = mean_squared_error(y_test, xgb_y_pred)\n",
    "  rmse = da.sqrt(mse)  # Compute RMSE from MSE\n",
    "  r2 = r2_score(y_test, xgb_y_pred)  # Compute R²\n",
    "\n",
    "  print(f\"RMSE: {rmse}\")\n",
    "  print(f\"R² score: {r2}\")\n",
    "\n",
    "\n",
    "  scores = cross_val_score(xgb, X_train, y_train, cv=5)\n",
    "\n",
    "  print(f\"Cross-validation scores: {scores}\")\n",
    "  print(f\"Average score: {scores.mean()}\")\n",
    "  \n",
    "  info['rmse'] = rmse\n",
    "  info['r2'] = r2\n",
    "  info['cross_val_scores'] = scores\n",
    "  info['average_score'] = scores.mean()\n",
    "  return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info_1_1_32 = xgbWith(cpus=1, threads=1, mem_per_partition='2GB', load_block_size='32MB', partition_size='32MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restarting existing Dask Client...\n",
      "Dask Client restarted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 50345 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard link: http://127.0.0.1:50345/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gethostbyname(socket.getfqdn()) failed... trying on hostname()\n",
      "Exception in thread Thread-5 (join):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/tracker.py\", line 365, in join\n",
      "    while self.thread.isAlive():\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Thread' object has no attribute 'isAlive'. Did you mean: 'is_alive'?\n",
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/__init__.py:7: UserWarning: Dask-XGBoost has been deprecated and is no longer maintained. The functionality of this project has been included directly in XGBoost. To use Dask and XGBoost together, please use ``xgboost.dask`` instead https://xgboost.readthedocs.io/en/latest/tutorials/dask.html.\n",
      "  warnings.warn(\n",
      "[20:29:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:06] WARNING: src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:06] Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:07] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/__init__.py:7: UserWarning: Dask-XGBoost has been deprecated and is no longer maintained. The functionality of this project has been included directly in XGBoost. To use Dask and XGBoost together, please use ``xgboost.dask`` instead https://xgboost.readthedocs.io/en/latest/tutorials/dask.html.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:29:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/__init__.py:7: UserWarning: Dask-XGBoost has been deprecated and is no longer maintained. The functionality of this project has been included directly in XGBoost. To use Dask and XGBoost together, please use ``xgboost.dask`` instead https://xgboost.readthedocs.io/en/latest/tutorials/dask.html.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE: 7.07746587557694\n",
      "R² score: -1.626744976532423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gethostbyname(socket.getfqdn()) failed... trying on hostname()\n",
      "Exception in thread Thread-7 (join):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/tracker.py\", line 365, in join\n",
      "    while self.thread.isAlive():\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Thread' object has no attribute 'isAlive'. Did you mean: 'is_alive'?\n",
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/__init__.py:7: UserWarning: Dask-XGBoost has been deprecated and is no longer maintained. The functionality of this project has been included directly in XGBoost. To use Dask and XGBoost together, please use ``xgboost.dask`` instead https://xgboost.readthedocs.io/en/latest/tutorials/dask.html.\n",
      "  warnings.warn(\n",
      "[20:29:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:12] WARNING: src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:12] Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gethostbyname(socket.getfqdn()) failed... trying on hostname()\n",
      "Exception in thread Thread-9 (join):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/tracker.py\", line 365, in join\n",
      "    while self.thread.isAlive():\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Thread' object has no attribute 'isAlive'. Did you mean: 'is_alive'?\n",
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/__init__.py:7: UserWarning: Dask-XGBoost has been deprecated and is no longer maintained. The functionality of this project has been included directly in XGBoost. To use Dask and XGBoost together, please use ``xgboost.dask`` instead https://xgboost.readthedocs.io/en/latest/tutorials/dask.html.\n",
      "  warnings.warn(\n",
      "[20:29:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:16] WARNING: src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:16] Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:17] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "WARNING:root:gethostbyname(socket.getfqdn()) failed... trying on hostname()\n",
      "Exception in thread Thread-11 (join):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/tracker.py\", line 365, in join\n",
      "    while self.thread.isAlive():\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Thread' object has no attribute 'isAlive'. Did you mean: 'is_alive'?\n",
      "[20:29:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:19] WARNING: src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:19] Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "WARNING:root:gethostbyname(socket.getfqdn()) failed... trying on hostname()\n",
      "Exception in thread Thread-13 (join):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/tracker.py\", line 365, in join\n",
      "    while self.thread.isAlive():\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Thread' object has no attribute 'isAlive'. Did you mean: 'is_alive'?\n",
      "[20:29:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:23] WARNING: src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:23] Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "WARNING:root:gethostbyname(socket.getfqdn()) failed... trying on hostname()\n",
      "Exception in thread Thread-15 (join):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/dask_xgboost/tracker.py\", line 365, in join\n",
      "    while self.thread.isAlive():\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Thread' object has no attribute 'isAlive'. Did you mean: 'is_alive'?\n",
      "[20:29:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:26] WARNING: src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:26] Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[20:29:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:29:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Cross-validation scores: [0.03776159        nan        nan        nan        nan]\n",
      "Average score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithreddykota/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "info_8_1_64 = xgbWith(cpus=8, threads=1, mem_per_partition='2GB', load_block_size='64MB', partition_size='64MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
